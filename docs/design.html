<!DOCTYPE HTML>
<!--
	Escape Velocity by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>GPU Design</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<script type="text/javascript"
  		src="assets/js/LaTeXMathML.js">
  		</script>
	</head>
	<body class="no-sidebar is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<section id="header" class="wrapper">

					<!-- Logo -->
						<div id="logo">
							<h1><a href="index.html">GPU Design</a></h1>
							<p>Delve deeper into GPU Design</p>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li class="current"><a href="index.html">Home</a></li>
								<li><a href="graphics.html">Raster Graphics</a></li>
								<li><a href="rays.html">Ray Tracing</a></li>
								<li><a href="design.html">GPU Design</a></li>
								<li><a href="resources.html">Resources</a></li>
							</ul>
						</nav>

				</section>

			<!-- Main -->
				<div id="main" class="wrapper style2">
					<div class="title">Design</div>
					<div class="container">

						<!-- Content -->
							<div id="content">
								<article class="box post">
									<!-- <header class="style1">
										<h2>Lorem ipsum dolor sit amet magna egestas<br class="mobile-hide" />
										morbi bibendum sed malesuada</h2>
										<p>Tempus feugiat veroeros sed nullam dolore</p>
									</header> -->
									<!-- <a href="#" class="image featured">
										<img src="images/pic01.jpg" alt="" />
									</a> -->
									<p>The software graphics pipeline workflow already demonstrates the vast amount
									 of parallel operations that could be done within the graphics pipeline. The transformation of a single
									 vertex is a multiply-accumulate operation between each entry of each row of a transformation
									matrix and each entry of the vertex position vector. For a single 3D object, each of the
									triangular faces that make up its surface would individually applied cross product
									to obtain its normal vector and dot product to calculate how illuminated it will be.
									Vertices's projection from the 3D model space to the 2D screen space is another
									chunk of heavy matrix multiplications. The interpolation and rasterization step also
									needs to worked on over as many faces as there are to make up the 3D object.</p>

									<p>Additionally, we can see how this architecture would benefit from hardware multithreading. This added
									functionality would allow it to quickly switch between tasks while data is loaded, prepared, utilized, and stored.
								As a result, the throughput of the system could increase dramatically for the price of only additional register files and virtual memory.  </p>

									<h2>Modern GPGPU Design</h2>
									<p>Though GPUs now utilize a variety of data flows, ranging from MIMD (Multiple Instructions,
									Multiple Data) to SISD (Single Instruction, Single Data), they were originally designed to
									speed up SIMD (Single Instruction, Multiple Data). It is quite easy to see how this data flow
									would benefit from enormous parallelism; the processor can take one instruction and perform the
									corresponding operation on thousands of bits of data, much as matrix multiplication is just
									performing one operation on many individual elements and vectors. As a result, we begin by
									designing a single SIMD unit. This unit takes our instruction and requests all of the necessary
									data from the register file in order to perform that instruction as quickly as possible on all
									of the data. This paradigm is especially useful for matrix multiplication as every entry of a
									resulting vector represents an independent data flow that can be operated on by the same instruction.</p>
									<center>
									<img src="images/eq8.JPG" style="width: 25%"></img>
									<p>$1(x) + 0(y) + 0(z) + 1(x_t) = x+x_t$</p>
									<p>$0(x) + 1(y) + 0(z) + 1(y_t) = y+y_t$</p>
									<p>$0(x) + 0(y) + 1(z) + 1(z_t) = z+z_t$</p>
									<p>$0(x) + 0(y) + 0(z) + 1(1) = 1$</p>
									</center>
									<p>As these equations illustrate, multiplication by a translation matrix can be broken up
									into four equations that execute the same arithmetic operations on four sets of independent
									data with four independent outputs. </p>
									<p>By combining similar rays into packets, we can again take advantage of the parallelism existing
										within GPUs and specifically the SIMD architecture.</p>
									<p>
										The SIMD structure also allows for the testing of four rays against each box and primitive simultaneously. This proves
										especially useful if we are testing multiple identical rays, perhaps to acheive greater accuracy and eliminate
										the need for denoising, although it also proves useful when testing with multiple rays that are similar but not
										identical as well. The rays will follow a more similar path through the ray tracing acceleration structure if they
										are more similar, increasing SIMD utilization from between 25% to 100% for a 4-wide SIMD structure.
										For reference, the new real-time ray tracing hardware available today must rely on a small number of rays per
										pixel in addition to image reconstruction and denoising to produce photorealistic images.
									</p>
									<h2>nVidia Turing Architecture</h2>
									<h3>Hybrid Rendering</h3>
									<center><figure>
										<img src="images/hybrid_pipeline.jpg" style="width:70%">
										<figcaption>Image from SEED Division of EA from Digital Dragons 2018 Presentation</figcaption>
									</figure></center>
									<h3>RT Cores</h3>
									<p>In addition to traditional fine grained multithreaded SIMD processors, nVidia's most recent <a href="https://www.nvidia.com/en-us/design-visualization/technologies/turing-architecture/">Turing
									Architecture</a> incorporate a hardware acceleration for performing ray tracing routines. nVidia calls each one of this
									type of special hardware module RT sore.
									</p>
									<p>
									RT cores allows the traditionally software oriented BVH transversal and ray-triangle intersection test to become
									their own independent hardware process. While a SIMD shader would initiate the ray probe, that is, presumably figuring
									out the proper parametric equations for the light rays, the hardware would take the ray probe and recursively search
									through the bounding volume hierearchy until it reaches the primitive level to hand over the tasks for ray intersection
									hardware to determine a hit or no hit. The hit ultimately determined by the test would be returned
									to the shaders to proper shading. nVidia's Turing Architecture Whitepaper offers a good graphical
									comparison between Pascal Architecture (with no ray tracing hardware acceleration) and Turing Architecture(with ray tracing
									hardware acceleration). Shaders, as RT cores are in the middle of determining hits, is freed up to perform other
									tasks in parallel.
									</p>
									<center>
									<figure>
										<img src="images/pascal_rt_pipelineJPG.JPG	" style="width:50%">
										<img src="images/turing_rt_pipelineJPG.JPG" style="width:50%">
										<figcaption>Images from Page 37 on nVidia Turing GPU Architecture Whitepaper</figcaption>
									</figure>
									</center>
									<h3>Performance, Energy, and Area</h3>
									<p>As shown by the comparison of Pascal and Turing Streaming Processor(SP) designs, the latter significantly
									differs in its addition of tensor cores(not discussed in this project) and RT cores. It would be interesting to
									conduct a comparison between the two architectures.
									</p>
									<center>
										<figure>
											<img src="images/pascal_gp100_sm.JPG" width="600"><img src="images/turing_SM.JPG" width="300">
											<figcaption>Images from Page 13 on NVIDIA Tesla P100 Whitepaper and Page 18 on NVIDIA Turing GPU Architecture Whitepaper</figcaption>
										</figure>


									<p>Below is a table refered in NVIDIA Turing GPU Architecture Whitepaper that compares some of the technical aspects between
										two of the top echolon gaming graphics cards.
									</p>
									<table style="width:80%">
										<tr>
										  <th>GPU Features</th>
										  <th>GeForce GTX 1080</th>
										  <th>GeForce RTX 2080</th>
										</tr>
										<tr>
										  <td>Architecture</td>
										  <td>Pascal</td>
										  <td>Turing</td>
										</tr>
										<tr>
											<td>SMs</td>
											<td>20</td>
											<td>46</td>
										</tr>
										<tr>
											<td>CUDA Cores per SM</td>
											<td>128</td>
											<td>64</td>
										</tr>
										<tr>
											<td>CUDA Cores per GPU</td>
											<td>2560</td>
											<td>2944</td>
										</tr>
										<tr>
											<td>RT Cores</td>
											<td>N/A</td>
											<td>46</td>
										</tr>
										<tr>
											<td>GPU Base Clock MHz</td>
											<td>1607</td>
											<td>1515</td>
										</tr>
										<tr>
											<td>RTX-OPS (Tera-OPS)</td>
											<td>8.9</td>
											<td>60</td>
										</tr>
										<tr>
											<td>Ray-Cast (Giga Rays/sec)</td>
											<td>0.89</td>
											<td>8</td>
										</tr>
										<tr>
											<td>Frame Buffer Memory Size and Type</td>
											<td>8192 MB GDDR5X</td>
											<td>8192 MB GDDR6</td>
										</tr>
										<tr>
											<td>Memory Clock (Data Rate)</td>
											<td>10 Gbps</td>
											<td>14 Gbps</td>
										</tr>
										<tr>
											<td>Memory Bandwidth (GB/sec)</td>
											<td>320</td>
											<td>448</td>
										</tr>
										<tr>
											<td>L2 Cache Size</td>
											<td>2048 KB</td>
											<td>4096 KB</td>
										</tr>
										<tr>
											<td>Transistor Count</td>
											<td>7.2 Billion</td>
											<td>13.6 Billion</td>
										</tr>
										<tr>
											<td>Die Size</td>
											<td>314 mm²</td>
											<td>545 mm²</td>
										</tr>
										<tr>
											<td>Thermal Design Power</td>
											<td>180 W</td>
											<td>225 W</td>
										</tr>
										<tr>
											<td>Manufacturing Process</td>
											<td>16 nm</td>
											<td>12 nm</td>
										</tr>
									  </table>
									</center>
									<p>While there are fewer numbers of Streaming Multiprocessors(SM) in the Pascal Architecuture, each SM individually
									has more Streaming Processors(SP, CUDA core) than those in Turing. The decrease in the number of SP in Turing SMs processors reflects
								  the incorporation of RT Core and Tensor Core into each SM. The different Turing architecutre is thus capable of casting almost nine times
								  more rays than its Pascal counterpart could and perform almost six times more hybrid rendering operations(RTX-Ops). In the same time,
								  however, we shouldn't ignore the advances in memory for the new generation of graphics cards: RTX 2080 uses GDDR6 at 14 Gbps versus
								  GTX1080's GDDR5X at 10Gbps. RTX 2080 also has doubled the size of the its L2 cache compared to GTX1080</p>
								  <p>Not surprisingly, the higher performance also introduced higher energy comsumption. At their maximum, GTX 1080 would only produce
									  180W of power whereas RTX 2080 theoretically goes up to 225W, despite that the latter has a slightly lower base clock rate than
									  the former. RTX 2080 nearly doubles the amount of transistors at 13.6 billions versus 7.2 billion transistors of GTX 1080. The fact that 
									  RTX 2080 upgraded its manufacturing process to 12nm to 16nm, but it didn't help the chip to be still nearly twice the size of
									  that inside GTX 1080.
								  </p>
								</article>
							</div>

					</div>
				</div>

			<!-- Highlights -->
				<!-- <section id="highlights" class="wrapper style3">
					<div class="title">The Endorsements</div>
					<div class="container">
						<div class="row aln-center">
							<div class="col-4 col-12-medium">
								<section class="highlight">
									<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
									<h3><a href="#">Aliquam diam consequat</a></h3>
									<p>Eget mattis at, laoreet vel amet sed velit aliquam diam ante, dolor aliquet sit amet vulputate mattis amet laoreet lorem.</p>
									<ul class="actions">
										<li><a href="#" class="button style1">Learn More</a></li>
									</ul>
								</section>
							</div>
							<div class="col-4 col-12-medium">
								<section class="highlight">
									<a href="#" class="image featured"><img src="images/pic03.jpg" alt="" /></a>
									<h3><a href="#">Nisl adipiscing sed lorem</a></h3>
									<p>Eget mattis at, laoreet vel amet sed velit aliquam diam ante, dolor aliquet sit amet vulputate mattis amet laoreet lorem.</p>
									<ul class="actions">
										<li><a href="#" class="button style1">Learn More</a></li>
									</ul>
								</section>
							</div>
							<div class="col-4 col-12-medium">
								<section class="highlight">
									<a href="#" class="image featured"><img src="images/pic04.jpg" alt="" /></a>
									<h3><a href="#">Mattis tempus lorem</a></h3>
									<p>Eget mattis at, laoreet vel amet sed velit aliquam diam ante, dolor aliquet sit amet vulputate mattis amet laoreet lorem.</p>
									<ul class="actions">
										<li><a href="#" class="button style1">Learn More</a></li>
									</ul>
								</section>
							</div>
						</div>
					</div>
				</section> -->

				<!-- Footer -->
				<section id="footer" class="wrapper">
						<div class="title">Contact Us</div>
						<div class="container">
							<header class="style1">
								<h2>Would you like to hear more about the project or contact the creators?</h2>
								<p>
									Please email us and we will do our best to get back to you.
								</p>
							</header>
								<div class="col-6 col-12-medium">

									<!-- Contact -->
										<section class="feature-list small">
											<div class="row">
												<div class="col-6 col-12-small">
													<section>
														<h3 class="icon fa-envelope">Email</h3>
														<p>
															dconnolly@olin.edu<br />
															qdeng@olin.edu
														</p>
													</section>
													<section>
														<h3 class="icon fa-home">Mailing Address</h3>
														<p>
															Olin College of Engineering<br />
															1000 Olin Way<br />
															Needham, MA 02492
														</p>
													</section>
												</div>
											</div>
										</section>

								</div>
							</div>
							<div id="copyright">
								<ul>
									<li>&copy; Daniel Connolly & Josh Deng for Computer Architecture Fall 2018</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
								</ul>
							</div>
						</div>
					</section>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
